#!/usr/bin/env python3
"""
Depth sweep benchmark (synthetic): compare Pycaso-style polynomial stereo reconstruction
(direct polynomial + Soloff polynomial + LM identification) to OpenCV pinhole stereo calibration
and to a compact central 3D ray-field backend fitted from ground-truth poses.

This experiment is intentionally *not* about compression. It targets the regime where the
calibration target spans multiple depths (varying Z), which is typical in microscopic setups.

Inputs:
  - A dataset scene generated by the CPU renderer (ray-plane intersection) with GT correspondences:
      gt_charuco_corners.npz  (frame_id, corner_id, XYZ_world_mm, uv_left_px, uv_right_px)

Outputs:
  - JSON summary with per-method metrics
  - Plot: RMS Z-error vs depth
"""

from __future__ import annotations

import argparse
import json
from pathlib import Path

import numpy as np

from stereocomplex.api.stereo_reconstruction import StereoCentralRayFieldModel
from stereocomplex.cli.refine_corners import refine_dataset_scene
from stereocomplex.eval.pycaso_soloff import PycasoSoloffStereoModel
from stereocomplex.eval.soloff_poly import SoloffPolynomialModel
from stereocomplex.ray3d.central_stereo_ba import StereoFrameObservations, fit_central_stereo_rayfield_coeffs_fixed


def _rms(x: np.ndarray) -> float:
    x = np.asarray(x, dtype=np.float64).reshape(-1)
    if x.size == 0:
        return float("nan")
    return float(np.sqrt(np.mean(x**2)))


def _per_depth_stats(depth: np.ndarray, err: np.ndarray) -> dict[str, list[float]]:
    depth = np.asarray(depth, dtype=np.float64).reshape(-1)
    err = np.asarray(err, dtype=np.float64).reshape(-1)
    # Bin by unique frame mean depth (the dataset is discrete in Z).
    out_depth = []
    out_rms = []
    for z in sorted(set(np.round(depth, 6).tolist())):
        mask = np.isclose(depth, z)
        out_depth.append(float(z))
        out_rms.append(_rms(err[mask]))
    return {"depth_mm": out_depth, "rms": out_rms}


def _charuco_inner_corners_mm(meta: dict) -> np.ndarray:
    """
    Inner chessboard corners in the board frame (mm), consistent with the CPU generator.

    - Board is centered at (0,0) on its plane.
    - Corners span [-w/2,+w/2] and [-h/2,+h/2].
    - Corner ids are row-major in the (rows-1, cols-1) inner grid.
    """
    b = meta["board"]
    cols = int(b["squares_x"])
    rows = int(b["squares_y"])
    square = float(b["square_size_mm"])
    w_mm = square * float(cols)
    h_mm = square * float(rows)
    xs = (-0.5 * w_mm + square * np.arange(1, cols, dtype=np.float64))
    ys = (-0.5 * h_mm + square * np.arange(1, rows, dtype=np.float64))
    xx, yy = np.meshgrid(xs, ys)
    corners = np.stack(
        [
            xx.reshape(-1),
            yy.reshape(-1),
            np.zeros(((rows - 1) * (cols - 1),), dtype=np.float64),
        ],
        axis=-1,
    )
    return corners


def _guess_intrinsics(meta: dict, camera: str, image_size: tuple[int, int]) -> tuple[np.ndarray, np.ndarray]:
    pitch_um = float(meta["stereo"][camera]["sensor"]["pixel_pitch_um"])
    f_um = float(meta["sim_params"]["f_um"])
    f_px = f_um / pitch_um
    cx = image_size[0] / 2.0
    cy = image_size[1] / 2.0
    K_guess = np.array([[f_px, 0.0, cx], [0.0, f_px, cy], [0.0, 0.0, 1.0]], dtype=np.float64)
    dist_meta = meta["sim_params"].get(f"distortion_{camera}", {})
    dist_guess = np.array(
        [
            float(dist_meta.get("k1", 0.0)),
            float(dist_meta.get("k2", 0.0)),
            float(dist_meta.get("p1", 0.0)),
            float(dist_meta.get("p2", 0.0)),
            float(dist_meta.get("k3", 0.0)),
        ],
        dtype=np.float64,
    )
    return K_guess, dist_guess


def _fit_opencv_pinhole(
    uvL: list[np.ndarray],
    uvR: list[np.ndarray],
    XYZ: list[np.ndarray],
    image_size: tuple[int, int],
    meta: dict,
) -> tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
    import cv2  # type: ignore

    objpoints = [p.astype(np.float32) for p in XYZ]
    imgpointsL = [u.astype(np.float32) for u in uvL]
    imgpointsR = [u.astype(np.float32) for u in uvR]

    # Monocular calibrations with GT prior intrinsic guess.
    K_guess_L, dist_guess_L = _guess_intrinsics(meta, "left", image_size)
    K_guess_R, dist_guess_R = _guess_intrinsics(meta, "right", image_size)
    flags = cv2.CALIB_USE_INTRINSIC_GUESS | cv2.CALIB_FIX_PRINCIPAL_POINT
    _retL, K_L, dist_L, rvecsL, tvecsL = cv2.calibrateCamera(
        objpoints, imgpointsL, image_size, K_guess_L, dist_guess_L, flags=flags
    )
    _retR, K_R, dist_R, rvecsR, tvecsR = cv2.calibrateCamera(
        objpoints, imgpointsR, image_size, K_guess_R, dist_guess_R, flags=flags
    )

    # Stereo rig (fix intrinsics).
    flags = cv2.CALIB_FIX_INTRINSIC
    _retS, _K_L2, _dist_L2, _K_R2, _dist_R2, R_RL, t_RL, *_ = cv2.stereoCalibrate(
        objpoints, imgpointsL, imgpointsR, K_L, dist_L, K_R, dist_R, image_size, flags=flags
    )
    return K_L, dist_L, K_R, dist_R, R_RL, t_RL


def _triangulate_opencv(
    K_L: np.ndarray,
    dist_L: np.ndarray,
    K_R: np.ndarray,
    dist_R: np.ndarray,
    R_RL: np.ndarray,
    t_RL: np.ndarray,
    uvL: np.ndarray,
    uvR: np.ndarray,
) -> np.ndarray:
    import cv2  # type: ignore

    uvL = np.asarray(uvL, dtype=np.float64).reshape(-1, 2)
    uvR = np.asarray(uvR, dtype=np.float64).reshape(-1, 2)

    # Undistort to normalized coordinates.
    uL = cv2.undistortPoints(uvL.reshape(-1, 1, 2), K_L, dist_L).reshape(-1, 2)
    uR = cv2.undistortPoints(uvR.reshape(-1, 1, 2), K_R, dist_R).reshape(-1, 2)

    P1 = np.hstack([np.eye(3), np.zeros((3, 1))])  # left camera at origin
    P2 = np.hstack([R_RL, t_RL.reshape(3, 1)])

    X_h = cv2.triangulatePoints(P1, P2, uL.T, uR.T).T
    X = X_h[:, :3] / (X_h[:, 3:4] + 1e-12)
    return X


def main() -> int:
    ap = argparse.ArgumentParser()
    ap.add_argument("dataset_root", type=Path, help="Dataset root (contains train/scene_0000)")
    ap.add_argument("--scene", default="scene_0000")
    ap.add_argument("--split", default="train")
    ap.add_argument("--max-frames", type=int, default=0, help="Limit number of frames (0=all).")
    ap.add_argument(
        "--use-detections",
        action="store_true",
        help="Use OpenCV-detected ChArUco corners as measurements (more realistic).",
    )
    ap.add_argument(
        "--use-refined",
        action="store_true",
        help="Use rayfield_tps_robust to refine the ChArUco corners before calibration.",
    )
    ap.add_argument("--refine-lam", type=float, default=10.0, help="TPS λ when `--use-refined`.")
    ap.add_argument("--refine-huber", type=float, default=3.0, help="Huber c when `--use-refined`.")
    ap.add_argument("--refine-iters", type=int, default=3, help="IRLS iterations when `--use-refined`.")
    ap.add_argument("--degree", type=int, default=3, help="Polynomial degree for Pycaso/Soloff direct mapping.")
    ap.add_argument("--ridge", type=float, default=0.0, help="Ridge regularization for polynomial fit.")
    ap.add_argument("--nmax", type=int, default=10, help="Zernike order for 3D ray-field BA.")
    ap.add_argument("--ray-outer-iters", type=int, default=3)
    ap.add_argument("--out-json", type=Path, default=Path("paper/tables/z_sweep_metrics.json"))
    ap.add_argument("--out-plot", type=Path, default=Path("paper/figures/z_sweep_rms_z.png"))
    args = ap.parse_args()

    scene_dir = args.dataset_root / args.split / args.scene
    meta = json.loads((scene_dir / "meta.json").read_text())
    w = int(meta["stereo"]["left"]["image"]["width_px"])
    h = int(meta["stereo"]["left"]["image"]["height_px"])

    gt = np.load(scene_dir / "gt_charuco_corners.npz")
    frame_id_gt = gt["frame_id"].astype(np.int32)
    corner_id_gt = gt["corner_id"].astype(np.int32)
    XYZ_gt = gt["XYZ_world_mm"].astype(np.float64)
    uvL_gt = gt["uv_left_px"].astype(np.float64)
    uvR_gt = gt["uv_right_px"].astype(np.float64)

    # Map GT by (frame_id, corner_id) for fast lookup.
    gt_key = frame_id_gt.astype(np.int64) * 1_000_000 + corner_id_gt.astype(np.int64)
    gt_xyz_by_key = {int(k): XYZ_gt[i] for i, k in enumerate(gt_key.tolist())}

    corners_board = _charuco_inner_corners_mm(meta)  # (K,3)
    if corner_id_gt.size and int(np.max(corner_id_gt)) >= corners_board.shape[0]:
        raise ValueError("corner_id exceeds board inner-corner count; check dataset/meta consistency.")

    # Frames present in GT.
    fids = sorted(set(frame_id_gt.tolist()))
    if args.max_frames and args.max_frames > 0:
        fids = fids[: int(args.max_frames)]

    if args.use_refined:
        refined = refine_dataset_scene(
            dataset_root=args.dataset_root,
            split=args.split,
            scene=args.scene,
            method="rayfield_tps_robust",
            max_frames=args.max_frames,
            tps_lam=float(args.refine_lam),
            huber_c=float(args.refine_huber),
            iters=int(args.refine_iters),
        )
        obs_frame_id = []
        obs_corner_id = []
        obs_uvL = []
        obs_uvR = []
        obs_XYZ = []
        for entry in refined["frames"]:
            fid = int(entry["frame_id"])
            if "left" not in entry or "right" not in entry:
                continue
            left = entry["left"]
            right = entry["right"]
            idsL = np.asarray(left["charuco_ids"], dtype=np.int32)
            idsR = np.asarray(right["charuco_ids"], dtype=np.int32)
            # `refine_dataset_scene()` already returns coordinates in the repository's
            # dataset convention (i.e., OpenCV ChArUco shift has already been applied).
            xyL = np.asarray(left["charuco_xy_refined"], dtype=np.float64)
            xyR = np.asarray(right["charuco_xy_refined"], dtype=np.float64)
            mapL = {int(i): xyL[k] for k, i in enumerate(idsL.tolist())}
            mapR = {int(i): xyR[k] for k, i in enumerate(idsR.tolist())}
            common = sorted(set(mapL).intersection(mapR))
            if not common:
                continue
            for cid in common:
                key = fid * 1_000_000 + cid
                if key not in gt_xyz_by_key:
                    continue
                obs_frame_id.append(fid)
                obs_corner_id.append(cid)
                obs_uvL.append(mapL[cid])
                obs_uvR.append(mapR[cid])
                obs_XYZ.append(gt_xyz_by_key[key])
        if not obs_frame_id:
            raise RuntimeError("No refined correspondences; cannot run benchmark.")
        frame_id = np.asarray(obs_frame_id, dtype=np.int32)
        corner_id = np.asarray(obs_corner_id, dtype=np.int32)
        XYZ = np.asarray(obs_XYZ, dtype=np.float64).reshape(-1, 3)
        uvL = np.asarray(obs_uvL, dtype=np.float64).reshape(-1, 2)
        uvR = np.asarray(obs_uvR, dtype=np.float64).reshape(-1, 2)
        fids = sorted(set(frame_id.tolist()))
    elif args.use_detections:
        # Use detected corners as measurements; GT supplies the corresponding 3D points.
        from stereocomplex.cli.refine_corners import build_charuco_from_meta, load_frames

        cv2, aruco, dictionary, board, detector_params, aruco_detector, charuco_detector = build_charuco_from_meta(meta)
        frames_info = load_frames(scene_dir)
        frames_info = [f for f in frames_info if int(f["frame_id"]) in set(fids)]

        obs_frame_id = []
        obs_corner_id = []
        obs_uvL = []
        obs_uvR = []
        obs_XYZ = []

        for fr in frames_info:
            fid = int(fr["frame_id"])
            imgL = cv2.imread(str(scene_dir / "left" / str(fr["left"])), cv2.IMREAD_GRAYSCALE)
            imgR = cv2.imread(str(scene_dir / "right" / str(fr["right"])), cv2.IMREAD_GRAYSCALE)
            if imgL is None or imgR is None:
                continue

            def detect(img):
                if charuco_detector is not None:
                    charuco_corners, charuco_ids, *_ = charuco_detector.detectBoard(img)
                else:
                    corners, ids, _rej = aruco_detector.detectMarkers(img)
                    if ids is None or len(ids) == 0:
                        return np.zeros((0,), np.int32), np.zeros((0, 2), np.float64)
                    ret = aruco.interpolateCornersCharuco(corners, ids, img, board)
                    if ret is None:
                        return np.zeros((0,), np.int32), np.zeros((0, 2), np.float64)
                    if len(ret) == 3:
                        charuco_corners, charuco_ids, _ = ret
                    else:
                        _, charuco_corners, charuco_ids, _ = ret
                if charuco_ids is None or charuco_corners is None or len(charuco_ids) == 0:
                    return np.zeros((0,), np.int32), np.zeros((0, 2), np.float64)
                ids = np.asarray(charuco_ids, dtype=np.int32).reshape(-1)
                xy = np.asarray(charuco_corners, dtype=np.float64).reshape(-1, 2)
                # Match the dataset convention used by GT (see `docs/CONVENTIONS.md`).
                xy = xy - 0.5
                return ids, xy

            idsL, xyL = detect(imgL)
            idsR, xyR = detect(imgR)
            if idsL.size == 0 or idsR.size == 0:
                continue
            mapL = {int(i): xyL[k] for k, i in enumerate(idsL.tolist())}
            mapR = {int(i): xyR[k] for k, i in enumerate(idsR.tolist())}
            common = sorted(set(mapL).intersection(mapR))
            if not common:
                continue

            for cid in common:
                key = int(fid) * 1_000_000 + int(cid)
                if key not in gt_xyz_by_key:
                    continue
                obs_frame_id.append(fid)
                obs_corner_id.append(cid)
                obs_uvL.append(mapL[cid])
                obs_uvR.append(mapR[cid])
                obs_XYZ.append(gt_xyz_by_key[key])

        if not obs_frame_id:
            raise RuntimeError("No detected correspondences; cannot run benchmark.")

        frame_id = np.asarray(obs_frame_id, dtype=np.int32)
        corner_id = np.asarray(obs_corner_id, dtype=np.int32)
        XYZ = np.asarray(obs_XYZ, dtype=np.float64).reshape(-1, 3)
        uvL = np.asarray(obs_uvL, dtype=np.float64).reshape(-1, 2)
        uvR = np.asarray(obs_uvR, dtype=np.float64).reshape(-1, 2)
        fids = sorted(set(frame_id.tolist()))
    else:
        # Use ground-truth pixel coordinates (best-case measurement).
        mask_keep = np.isin(frame_id_gt, np.asarray(fids, dtype=np.int32))
        frame_id = frame_id_gt[mask_keep]
        corner_id = corner_id_gt[mask_keep]
        XYZ = XYZ_gt[mask_keep]
        uvL = uvL_gt[mask_keep]
        uvR = uvR_gt[mask_keep]

    # Split frames: even frame ids for training, odd for test.
    train_fids = {fid for fid in fids if (fid % 2 == 0)}
    test_fids = {fid for fid in fids if (fid % 2 == 1)}
    if not test_fids:
        # Fallback: leave last frame as test
        test_fids = {fids[-1]}
        train_fids = set(fids[:-1])

    is_train = np.isin(frame_id, np.fromiter(train_fids, dtype=np.int32))
    is_test = np.isin(frame_id, np.fromiter(test_fids, dtype=np.int32))

    # ---- Pycaso: direct polynomial mapping (Eq. 2.1 in Caron et al., SoftwareX 2023)
    pycaso_direct = SoloffPolynomialModel.fit(
        uv_left_px=uvL[is_train],
        uv_right_px=uvR[is_train],
        XYZ_mm=XYZ[is_train],
        degree=int(args.degree),
        ridge=float(args.ridge),
    )
    XYZ_direct = pycaso_direct.predict(uvL[is_test], uvR[is_test])

    e_direct = XYZ_direct - XYZ[is_test]
    ez_direct = e_direct[:, 2]
    depth_test = XYZ[is_test][:, 2]

    # ---- Pycaso: Soloff calibration + LM identification (Eq. 2.4–2.5)
    pycaso_soloff = PycasoSoloffStereoModel.fit(
        XYZ_mm=XYZ[is_train],
        uv_left_px=uvL[is_train],
        uv_right_px=uvR[is_train],
        degree=int(args.degree),
        ridge=float(args.ridge),
    )
    XYZ_soloff = pycaso_soloff.solve(uvL[is_test], uvR[is_test])
    e_soloff = XYZ_soloff - XYZ[is_test]
    ez_soloff = e_soloff[:, 2]

    # ---- OpenCV pinhole
    uvL_frames = []
    uvR_frames = []
    P_board_frames = []
    for fid in sorted(train_fids | test_fids):
        sel = frame_id == fid
        uvL_frames.append(uvL[sel])
        uvR_frames.append(uvR[sel])
        P_board_frames.append(corners_board[corner_id[sel]].astype(np.float64))

    K_L, dist_L, K_R, dist_R, R_RL, t_RL = _fit_opencv_pinhole(
        uvL_frames, uvR_frames, P_board_frames, image_size=(w, h), meta=meta
    )
    XYZ_cv = _triangulate_opencv(K_L, dist_L, K_R, dist_R, R_RL, t_RL, uvL[is_test], uvR[is_test])
    e_cv = XYZ_cv - XYZ[is_test]
    ez_cv = e_cv[:, 2]

    # ---- 3D ray-field backend (central), with fixed rig + fixed per-frame poses (synthetic-only benchmark).
    frames: dict[int, StereoFrameObservations] = {}
    gt_pose_by_frame: dict[int, tuple[np.ndarray, np.ndarray]] = {}

    def rigid_align(P: np.ndarray, Q: np.ndarray) -> tuple[np.ndarray, np.ndarray]:
        P = np.asarray(P, dtype=np.float64).reshape(-1, 3)
        Q = np.asarray(Q, dtype=np.float64).reshape(-1, 3)
        if P.shape[0] != Q.shape[0] or P.shape[0] < 3:
            raise ValueError("Need >=3 correspondences for rigid alignment.")
        Pc = P - np.mean(P, axis=0, keepdims=True)
        Qc = Q - np.mean(Q, axis=0, keepdims=True)
        H = Pc.T @ Qc
        U, _S, Vt = np.linalg.svd(H)
        Rm = Vt.T @ U.T
        if np.linalg.det(Rm) < 0:
            Vt[-1, :] *= -1
            Rm = Vt.T @ U.T
        t = (np.mean(Q, axis=0) - Rm @ np.mean(P, axis=0)).reshape(3)
        return Rm, t

    for fid in sorted(train_fids):
        sel = frame_id == fid
        P_board = corners_board[corner_id[sel]].astype(np.float64)
        frames[int(fid)] = StereoFrameObservations(uv_left_px=uvL[sel], uv_right_px=uvR[sel], P_board_mm=P_board)
        Rm, t = rigid_align(P_board, XYZ[sel])
        gt_pose_by_frame[int(fid)] = (Rm, t)

    # Init: per-frame board pose from GT rigid alignment (this benchmark is synthetic-only).
    from scipy.spatial.transform import Rotation as R  # type: ignore

    rvecs0 = {fid: R.from_matrix(gt_pose_by_frame[fid][0]).as_rotvec() for fid in frames}
    tvecs0 = {fid: gt_pose_by_frame[fid][1] for fid in frames}
    rig_rvec0 = np.zeros((3,), dtype=np.float64)
    baseline_mm = float(meta["sim_params"]["baseline_mm"])
    # Convention in our ray model: P_R = R_RL P_L + t_RL, with C_R = -R_RL^T t_RL.
    # For the synthetic generator where the right camera is shifted by +baseline along X in the left frame,
    # the corresponding translation is t_RL = (-baseline, 0, 0).
    rig_tvec0 = np.array([-baseline_mm, 0.0, 0.0], dtype=np.float64)

    # Get exact K from one design matrix via the helper in fit function by passing coeffs0 of the right size.
    # We just build coeff vectors from modes count inferred internally by providing zeros of sufficient length;
    # fit function will validate and use the effective K from design matrices, so we build via first frame.
    # Here we simply allocate from the first frame's design matrix size.
    from stereocomplex.core.model_compact.zernike import zernike_design_matrix
    from stereocomplex.ray3d.central_ba import default_disk

    u0_px, v0_px, radius_px = default_disk(int(w), int(h))

    def init_coeffs_from_pinhole_xy(uv: np.ndarray) -> tuple[np.ndarray, np.ndarray]:
        uv = np.asarray(uv, dtype=np.float64).reshape(-1, 2)
        # Approximate focal length in pixels (synthetic meta is known here).
        try:
            f_um = float(meta["sim_params"]["f_um"])
            pitch_um = float(meta["stereo"]["left"]["sensor"]["pixel_pitch_um"])
            f_px = f_um / pitch_um
        except Exception:
            f_px = 1.5 * float(max(w, h))
        x_tgt = (uv[:, 0] - float(u0_px)) / float(f_px)
        y_tgt = (uv[:, 1] - float(v0_px)) / float(f_px)
        A, _mask, _modes = zernike_design_matrix(
            uv[:, 0], uv[:, 1], nmax=int(args.nmax), u0_px=float(u0_px), v0_px=float(v0_px), radius_px=float(radius_px)
        )
        cx, *_ = np.linalg.lstsq(A, x_tgt, rcond=None)
        cy, *_ = np.linalg.lstsq(A, y_tgt, rcond=None)
        return np.asarray(cx, dtype=np.float64).reshape(-1), np.asarray(cy, dtype=np.float64).reshape(-1)

    # Initialize coefficients from a pinhole guess using all training-frame pixels (stabilizes BA a lot).
    uvL_all = np.concatenate([frames[fid].uv_left_px for fid in frames], axis=0)
    uvR_all = np.concatenate([frames[fid].uv_right_px for fid in frames], axis=0)
    coeff0_Lx, coeff0_Ly = init_coeffs_from_pinhole_xy(uvL_all)
    coeff0_Rx, coeff0_Ry = init_coeffs_from_pinhole_xy(uvR_all)
    Keff = int(coeff0_Lx.size)

    rf = fit_central_stereo_rayfield_coeffs_fixed(
        frames=frames,
        image_width_px=w,
        image_height_px=h,
        nmax=int(args.nmax),
        rvecs=rvecs0,
        tvecs=tvecs0,
        rig_rvec=rig_rvec0,
        rig_tvec=rig_tvec0,
        coeffs0_left_x=coeff0_Lx,
        coeffs0_left_y=coeff0_Ly,
        coeffs0_right_x=coeff0_Rx,
        coeffs0_right_y=coeff0_Ry,
        max_nfev=200,
    )
    model = StereoCentralRayFieldModel.from_coeffs(
        image_width_px=w,
        image_height_px=h,
        nmax=int(rf.nmax),
        u0_px=float(rf.u0_px),
        v0_px=float(rf.v0_px),
        radius_px=float(rf.radius_px),
        coeffs_left_x=rf.coeffs_left_x,
        coeffs_left_y=rf.coeffs_left_y,
        coeffs_right_x=rf.coeffs_right_x,
        coeffs_right_y=rf.coeffs_right_y,
        R_RL=np.asarray(R.from_rotvec(rf.rig_rvec).as_matrix(), dtype=np.float64),
        t_RL=np.asarray(rf.rig_tvec, dtype=np.float64),
    )
    XYZ_ray, skew = model.triangulate(uvL[is_test], uvR[is_test])
    e_ray = XYZ_ray - XYZ[is_test]
    ez_ray = e_ray[:, 2]

    # Summaries.
    summary = {
        "split": {"train_frames": sorted(train_fids), "test_frames": sorted(test_fids)},
        "depth_mm": {"min": float(np.min(depth_test)), "max": float(np.max(depth_test))},
        "pycaso_direct_poly": {
            "degree": int(args.degree),
            "ridge": float(args.ridge),
            "rms_xyz_mm": [float(_rms(e_direct[:, i])) for i in range(3)],
            "rms_z_mm": float(_rms(ez_direct)),
            "by_depth": _per_depth_stats(depth_test, ez_direct),
        },
        "pycaso_soloff_lm": {
            "degree": int(args.degree),
            "ridge": float(args.ridge),
            "rms_xyz_mm": [float(_rms(e_soloff[:, i])) for i in range(3)],
            "rms_z_mm": float(_rms(ez_soloff)),
            "by_depth": _per_depth_stats(depth_test, ez_soloff),
        },
        "opencv_pinhole": {
            "rms_xyz_mm": [float(_rms(e_cv[:, i])) for i in range(3)],
            "rms_z_mm": float(_rms(ez_cv)),
            "by_depth": _per_depth_stats(depth_test, ez_cv),
        },
        "rayfield3d_fixed": {
            "nmax": int(args.nmax),
            "rms_xyz_mm": [float(_rms(e_ray[:, i])) for i in range(3)],
            "rms_z_mm": float(_rms(ez_ray)),
            "skew_p95_mm": float(np.quantile(skew, 0.95)) if skew.size else float("nan"),
            "by_depth": _per_depth_stats(depth_test, ez_ray),
        },
    }

    args.out_json.parent.mkdir(parents=True, exist_ok=True)
    args.out_json.write_text(json.dumps(summary, indent=2, sort_keys=True))
    print(f"Wrote {args.out_json}")

    # Plot.
    import matplotlib.pyplot as plt

    fig, ax = plt.subplots(figsize=(7.5, 4.0), constrained_layout=True)
    for label, color, d in [
        ("Pycaso direct poly", "tab:orange", summary["pycaso_direct_poly"]["by_depth"]),
        ("Pycaso Soloff (LM)", "tab:purple", summary["pycaso_soloff_lm"]["by_depth"]),
        ("OpenCV pinhole", "tab:red", summary["opencv_pinhole"]["by_depth"]),
        ("3D ray-field (fixed poses)", "tab:blue", summary["rayfield3d_fixed"]["by_depth"]),
    ]:
        ax.plot(d["depth_mm"], d["rms"], marker="o", linewidth=2, label=label, color=color)
    ax.set_xlabel("Depth Z (mm)")
    ax.set_ylabel("RMS Z error (mm)")
    ax.set_title("Depth sweep: RMS Z error vs depth (synthetic)")
    ax.grid(True, alpha=0.25)
    ax.legend()

    args.out_plot.parent.mkdir(parents=True, exist_ok=True)
    fig.savefig(args.out_plot, dpi=200)
    print(f"Wrote {args.out_plot}")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
